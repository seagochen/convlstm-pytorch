#!/usr/bin/env python3
"""
FireConvLSTM æ¨ç†/æ£€æµ‹è„šæœ¬

Usage:
    # æ£€æµ‹å•ä¸ªè§†é¢‘æ–‡ä»¶å¤¹
    python detect.py --source /path/to/frames --weights best_model.pth

    # æ£€æµ‹å¤šä¸ªæ–‡ä»¶å¤¹
    python detect.py --source /path/to/data --weights best_model.pth --batch

    # ä¿å­˜å¯è§†åŒ–ç»“æœ
    python detect.py --source /path/to/frames --weights best_model.pth --save_viz --output ./results
"""

import os
import sys
import argparse
import cv2
import torch
import numpy as np
from pathlib import Path
from typing import List, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from convlstm import FireConvLSTM, create_model, heatmap_to_prob


def parse_args():
    parser = argparse.ArgumentParser(description='Fire detection inference using FireConvLSTM')

    parser.add_argument('--source', type=str, required=True,
                        help='è¾“å…¥æº: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--weights', type=str, required=True,
                        help='æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--seq_length', type=int, default=5,
                        help='åºåˆ—é•¿åº¦ (è¿ç»­å¸§æ•°)')
    parser.add_argument('--target_size', type=int, nargs=2, default=[640, 640],
                        help='ç›®æ ‡å›¾åƒå°ºå¯¸ (H, W)')
    parser.add_argument('--threshold', type=float, default=0.5,
                        help='ç«ç¾æ£€æµ‹é˜ˆå€¼')
    parser.add_argument('--device', type=str, default='auto',
                        help='æ¨ç†è®¾å¤‡ (cuda/cpu/auto)')

    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output', type=str, default='./results',
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--save_viz', action='store_true',
                        help='ä¿å­˜å¯è§†åŒ–ç»“æœ')
    parser.add_argument('--batch', action='store_true',
                        help='æ‰¹é‡å¤„ç†æ¨¡å¼ (source ä¸ºåŒ…å«å¤šä¸ªå­æ–‡ä»¶å¤¹çš„ç›®å½•)')

    return parser.parse_args()


def get_sorted_frames(folder_path: Path) -> List[Path]:
    """è·å–æ–‡ä»¶å¤¹ä¸­æŒ‰ç¼–å·æ’åºçš„å›¾ç‰‡åˆ—è¡¨"""
    import re

    def extract_frame_number(filename: str) -> int:
        match = re.search(r'frame_(\d+)', filename)
        if match:
            return int(match.group(1))
        match = re.search(r'(\d+)\.[^.]+$', filename)
        if match:
            return int(match.group(1))
        return -1

    image_extensions = {'.png', '.jpg', '.jpeg'}
    frames = [f for f in folder_path.iterdir() if f.suffix.lower() in image_extensions]
    frames.sort(key=lambda x: extract_frame_number(x.name))
    return frames


def load_and_preprocess(image_path: Path, target_size: Tuple[int, int]) -> np.ndarray:
    """åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡"""
    img = cv2.imread(str(image_path))
    if img is None:
        raise ValueError(f"Failed to load image: {image_path}")

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    if img.shape[:2] != target_size:
        img = cv2.resize(img, (target_size[1], target_size[0]), interpolation=cv2.INTER_LINEAR)

    img = img.transpose(2, 0, 1).astype(np.float32) / 255.0
    return img


def detect_folder(
    model: torch.nn.Module,
    folder_path: Path,
    seq_length: int,
    target_size: Tuple[int, int],
    device: torch.device,
    threshold: float = 0.5
) -> dict:
    """
    æ£€æµ‹å•ä¸ªæ–‡ä»¶å¤¹

    Returns:
        {
            'folder': str,
            'prediction': str,  # 'dynamic' or 'static'
            'probability': float,
            'heatmap': np.ndarray,  # (20, 20)
            'frames_used': List[str]
        }
    """
    frames_list = get_sorted_frames(folder_path)

    if len(frames_list) < seq_length:
        return {
            'folder': folder_path.name,
            'prediction': 'error',
            'probability': 0.0,
            'heatmap': None,
            'frames_used': [],
            'error': f'Not enough frames: {len(frames_list)} < {seq_length}'
        }

    # åŠ è½½æœ€å seq_length å¸§
    start_idx = len(frames_list) - seq_length
    frames = []
    for i in range(seq_length):
        frame = load_and_preprocess(frames_list[start_idx + i], target_size)
        frames.append(frame)

    frames = np.stack(frames, axis=0)  # (T, 3, H, W)
    frames_tensor = torch.from_numpy(frames).unsqueeze(0).to(device)  # (1, T, 3, H, W)

    # æ¨ç†
    model.eval()
    with torch.no_grad():
        heatmap = model(frames_tensor)  # (1, 1, 20, 20)
        prob = heatmap_to_prob(heatmap).item()

    prediction = 'dynamic' if prob > threshold else 'static'
    heatmap_np = heatmap[0, 0].cpu().numpy()

    return {
        'folder': folder_path.name,
        'prediction': prediction,
        'probability': prob,
        'heatmap': heatmap_np,
        'frames_used': [frames_list[start_idx + i].name for i in range(seq_length)]
    }


def visualize_result(
    result: dict,
    folder_path: Path,
    target_size: Tuple[int, int],
    output_path: Path
):
    """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
    import matplotlib.pyplot as plt

    if result['heatmap'] is None:
        return

    # åŠ è½½æœ€åä¸€å¸§
    frames_list = get_sorted_frames(folder_path)
    last_frame_path = frames_list[-1]
    last_frame = cv2.imread(str(last_frame_path))
    last_frame = cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB)

    if last_frame.shape[:2] != target_size:
        last_frame = cv2.resize(last_frame, (target_size[1], target_size[0]))

    # ä¸Šé‡‡æ ·çƒ­åŠ›å›¾
    heatmap = result['heatmap']
    heatmap_resized = cv2.resize(heatmap, (target_size[1], target_size[0]))

    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # åŸå›¾
    axes[0].imshow(last_frame)
    axes[0].set_title('Original Frame')
    axes[0].axis('off')

    # çƒ­åŠ›å›¾
    im = axes[1].imshow(heatmap, cmap='hot', vmin=0, vmax=1)
    axes[1].set_title(f'Heatmap (max={heatmap.max():.3f})')
    axes[1].axis('off')
    plt.colorbar(im, ax=axes[1], fraction=0.046)

    # å åŠ 
    axes[2].imshow(last_frame)
    axes[2].imshow(heatmap_resized, cmap='hot', alpha=0.5, vmin=0, vmax=1)
    pred_color = 'red' if result['prediction'] == 'dynamic' else 'green'
    axes[2].set_title(
        f"Prediction: {result['prediction'].upper()} ({result['probability']:.3f})",
        color=pred_color,
        fontweight='bold'
    )
    axes[2].axis('off')

    plt.suptitle(f"Folder: {result['folder']}", fontsize=14)
    plt.tight_layout()

    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()


def main():
    args = parse_args()

    # è®¾ç½®è®¾å¤‡
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)

    print(f"Device: {device}")
    print(f"Model: {args.weights}")

    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½æ¨¡å‹...")
    model = create_model(args.weights)
    model = model.to(device)
    model.eval()

    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,}")

    # è·å–è¦å¤„ç†çš„æ–‡ä»¶å¤¹åˆ—è¡¨
    source_path = Path(args.source)
    target_size = tuple(args.target_size)

    if args.batch:
        # æ‰¹é‡æ¨¡å¼: å¤„ç†å­æ–‡ä»¶å¤¹
        folders = [f for f in source_path.iterdir() if f.is_dir()]
        print(f"\næ‰¾åˆ° {len(folders)} ä¸ªå­æ–‡ä»¶å¤¹")
    else:
        # å•æ–‡ä»¶å¤¹æ¨¡å¼
        folders = [source_path]

    # æ£€æµ‹
    results = []
    print("\nå¼€å§‹æ£€æµ‹...")
    print("-" * 60)

    for folder in folders:
        result = detect_folder(
            model=model,
            folder_path=folder,
            seq_length=args.seq_length,
            target_size=target_size,
            device=device,
            threshold=args.threshold
        )
        results.append(result)

        # æ‰“å°ç»“æœ
        if 'error' in result:
            print(f"[ERROR] {result['folder']}: {result['error']}")
        else:
            status = 'ğŸ”¥' if result['prediction'] == 'dynamic' else 'âœ“'
            print(f"[{status}] {result['folder']}: {result['prediction'].upper()} "
                  f"(prob={result['probability']:.3f})")

        # ä¿å­˜å¯è§†åŒ–
        if args.save_viz and result['heatmap'] is not None:
            output_path = Path(args.output) / f"{result['folder']}_result.png"
            visualize_result(result, folder, target_size, output_path)

    # ç»Ÿè®¡
    print("-" * 60)
    print("\næ£€æµ‹ç»Ÿè®¡:")

    valid_results = [r for r in results if 'error' not in r]
    dynamic_count = sum(1 for r in valid_results if r['prediction'] == 'dynamic')
    static_count = len(valid_results) - dynamic_count

    print(f"  æ€»è®¡: {len(results)} ä¸ªæ–‡ä»¶å¤¹")
    print(f"  æˆåŠŸ: {len(valid_results)}")
    print(f"  Dynamic (çœŸç«): {dynamic_count}")
    print(f"  Static (å‡ç«): {static_count}")

    if args.save_viz:
        print(f"\nå¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {args.output}")


if __name__ == '__main__':
    main()
