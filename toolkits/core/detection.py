"""
Detection utilities for YOLO-based object detection and segmentation.

Provides Detection dataclass and helper functions for extracting
and processing YOLO detection results.
"""

import cv2
import numpy as np
from dataclasses import dataclass
from typing import List, Set, Tuple, Optional

from .constants import CLASS_COLORS, TRACK_COLORS


@dataclass
class Detection:
    """Detection result from YOLO model."""
    x1: float
    y1: float
    x2: float
    y2: float
    confidence: float
    class_id: int
    mask: Optional[np.ndarray] = None

    @classmethod
    def from_yolo_box(cls, box, mask_data: Optional[np.ndarray] = None) -> 'Detection':
        """
        Create Detection from YOLO box result.

        Args:
            box: YOLO box object with xyxy, conf, cls attributes
            mask_data: Optional segmentation mask array

        Returns:
            Detection instance
        """
        xyxy = box.xyxy[0].cpu().numpy()
        return cls(
            x1=float(xyxy[0]),
            y1=float(xyxy[1]),
            x2=float(xyxy[2]),
            y2=float(xyxy[3]),
            confidence=float(box.conf[0]),
            class_id=int(box.cls[0]),
            mask=mask_data
        )

    @property
    def bbox(self) -> Tuple[int, int, int, int]:
        """Return bbox as integer tuple (x1, y1, x2, y2)."""
        return (int(self.x1), int(self.y1), int(self.x2), int(self.y2))

    @property
    def width(self) -> float:
        """Return bbox width."""
        return self.x2 - self.x1

    @property
    def height(self) -> float:
        """Return bbox height."""
        return self.y2 - self.y1

    @property
    def area(self) -> float:
        """Return bbox area."""
        return self.width * self.height


def get_class_color(class_id: int) -> Tuple[int, int, int]:
    """
    Get a consistent color for a class ID.

    Args:
        class_id: Class identifier

    Returns:
        BGR color tuple
    """
    return CLASS_COLORS.get(class_id, TRACK_COLORS[class_id % len(TRACK_COLORS)])


def extract_detections_from_yolo(
    results,
    frame_shape: Tuple[int, int],
    active_classes: Set[int],
    conf_threshold: float = 0.5
) -> List[Detection]:
    """
    Extract Detection objects from YOLO segmentation results.

    Args:
        results: YOLO inference results
        frame_shape: (height, width) of frame
        active_classes: Set of class IDs to include
        conf_threshold: Minimum confidence threshold

    Returns:
        List of Detection objects with masks (if available)
    """
    h, w = frame_shape
    detections = []

    # Handle segmentation results (with masks)
    if hasattr(results, 'masks') and results.masks is not None:
        for box, mask in zip(results.boxes, results.masks.data):
            class_id = int(box.cls[0])
            conf = float(box.conf[0])

            if class_id in active_classes and conf >= conf_threshold:
                mask_np = mask.cpu().numpy()
                mask_resized = cv2.resize(mask_np, (w, h), interpolation=cv2.INTER_NEAREST)
                mask_binary = (mask_resized > 0.5).astype(np.uint8)

                det = Detection.from_yolo_box(box, mask_data=mask_binary)
                detections.append(det)

    # Handle detection results (boxes only)
    elif hasattr(results, 'boxes') and results.boxes is not None:
        for box in results.boxes:
            class_id = int(box.cls[0])
            conf = float(box.conf[0])

            if class_id in active_classes and conf >= conf_threshold:
                det = Detection.from_yolo_box(box)
                detections.append(det)

    return detections


def extract_bbox_detections(
    results,
    target_classes: Set[int],
    conf_threshold: float = 0.5
) -> List[Detection]:
    """
    Extract Detection objects from YOLO results (bbox only, no mask).

    Args:
        results: YOLO inference results
        target_classes: Set of class IDs to include
        conf_threshold: Minimum confidence threshold

    Returns:
        List of Detection objects (without masks)
    """
    detections = []

    if results.boxes is not None and len(results.boxes) > 0:
        for box in results.boxes:
            conf = float(box.conf[0])
            class_id = int(box.cls[0])

            if class_id in target_classes and conf >= conf_threshold:
                det = Detection.from_yolo_box(box)
                detections.append(det)

    return detections


def compute_bbox_union(
    bboxes: List[Tuple[float, float, float, float]]
) -> Optional[Tuple[int, int, int, int]]:
    """
    Compute union (bounding box that covers all input bboxes).

    Args:
        bboxes: List of (x1, y1, x2, y2) tuples

    Returns:
        Union bbox as (x1, y1, x2, y2) or None if no bboxes
    """
    if not bboxes:
        return None

    x1_min = min(bbox[0] for bbox in bboxes)
    y1_min = min(bbox[1] for bbox in bboxes)
    x2_max = max(bbox[2] for bbox in bboxes)
    y2_max = max(bbox[3] for bbox in bboxes)

    return (int(x1_min), int(y1_min), int(x2_max), int(y2_max))


def add_bbox_padding(
    bbox: Tuple[int, int, int, int],
    frame_shape: Tuple[int, int],
    padding_ratio: float = 0.05
) -> Tuple[int, int, int, int]:
    """
    Add padding to bbox and clamp to frame boundaries.

    Args:
        bbox: (x1, y1, x2, y2)
        frame_shape: (height, width)
        padding_ratio: Padding as ratio of bbox size

    Returns:
        Padded bbox (x1, y1, x2, y2)
    """
    h, w = frame_shape
    x1, y1, x2, y2 = bbox

    bbox_w = x2 - x1
    bbox_h = y2 - y1

    pad_w = int(bbox_w * padding_ratio)
    pad_h = int(bbox_h * padding_ratio)

    x1 = max(0, x1 - pad_w)
    y1 = max(0, y1 - pad_h)
    x2 = min(w, x2 + pad_w)
    y2 = min(h, y2 + pad_h)

    return (x1, y1, x2, y2)


def apply_bbox_mask(
    frame: np.ndarray,
    bbox: Tuple[int, int, int, int]
) -> np.ndarray:
    """
    Apply bbox mask to frame, setting pixels outside bbox to 0.

    Args:
        frame: Input frame (H, W, C)
        bbox: (x1, y1, x2, y2)

    Returns:
        Masked frame where only bbox region is visible
    """
    masked_frame = np.zeros_like(frame)
    x1, y1, x2, y2 = bbox
    masked_frame[y1:y2, x1:x2] = frame[y1:y2, x1:x2]
    return masked_frame


def apply_segmentation_mask(
    frame: np.ndarray,
    detections: List[Detection]
) -> np.ndarray:
    """
    Apply segmentation masks to frame, keeping only detected regions.
    Non-detected areas are set to black (0).

    Args:
        frame: Original frame (H, W, C)
        detections: List of detections with masks

    Returns:
        Masked frame where only detected regions are visible
    """
    if not detections:
        return np.zeros_like(frame)

    h, w = frame.shape[:2]
    combined_mask = np.zeros((h, w), dtype=np.uint8)

    for det in detections:
        if det.mask is not None:
            if det.mask.shape != (h, w):
                mask_resized = cv2.resize(
                    det.mask.astype(np.uint8), (w, h),
                    interpolation=cv2.INTER_NEAREST
                )
            else:
                mask_resized = det.mask.astype(np.uint8)
            combined_mask = np.maximum(combined_mask, mask_resized)

    masked_frame = frame.copy()
    masked_frame[combined_mask == 0] = 0

    return masked_frame
